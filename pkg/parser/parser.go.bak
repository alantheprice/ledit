package parser

import (
	"bufio"
	"fmt"
	"os"
	"regexp"
	"strconv"
	"strings"
	"time"
)

var (
	// startOfBlockRegex matches the beginning of a code block, e.g., ``` or ```go.
	// It now captures the language identifier (if present) in the first submatch.
	startOfBlockRegex    = regexp.MustCompile("^\\s*[>|]*```(\\S*)")
	hardEndOfBlockString = "```END" // Explicit end marker
)

// isHardEndOfCodeBlock checks if a line is the explicit "```END" marker.
func isHardEndOfCodeBlock(line string) bool {
	return strings.TrimSpace(line) == hardEndOfBlockString
}

// isStartOfCodeBlock checks if a line marks the beginning of a code block.
// It also returns the detected language (e.g., "go", "python", or empty string if none specified).
func isStartOfCodeBlock(line string) (bool, string) {
	// A line that is a hard end of block is never a start of block.
	if isHardEndOfCodeBlock(line) {
		return false, ""
	}
	matches := startOfBlockRegex.FindStringSubmatch(line)
	if len(matches) > 0 {
		// matches[0] is the full match, matches[1] is the captured language
		return true, strings.ToLower(matches[1]) // Return the captured language
	}
	return false, ""
}

// isEndOfCodeBlock checks if a line marks the end of a code block.
// It considers both the explicit "```END" marker and the "```" fallback,
// with the "```" fallback not applying to markdown blocks.
func isEndOfCodeBlock(line string, currentLanguage string) bool {
	if isHardEndOfCodeBlock(line) {
		return true
	}
	// Fallback for 3 backticks
	if strings.TrimSpace(line) == "```" {
		return true
	}
	return false
}

// IsPartialContentMarker checks if a line is a partial content marker.
// This function is now MUCH MORE CONSERVATIVE to avoid false positives that cause
// infinite retry loops. It only detects very obvious placeholder patterns.
func IsPartialContentMarker(line string) bool {
	lowerLine := strings.ToLower(strings.TrimSpace(line))

	// Only detect extremely obvious placeholder patterns that are clearly incomplete
	// These are patterns that indicate the LLM gave up or truncated the response
	obviosPlaceholderPatterns := []string{
		"... (rest of file unchanged)", // Very specific placeholder
		"... rest of the file ...",     // Common truncation pattern
		"// ... rest unchanged ...",    // Obvious placeholder comment
		"/* ... unchanged ... */",      // Block comment placeholder
		"... content truncated ...",    // Explicit truncation marker
		"... full file content ...",    // Obvious incomplete marker
	}

	// Only flag as partial if we find these very specific patterns
	for _, pattern := range obviosPlaceholderPatterns {
		if strings.Contains(lowerLine, pattern) {
			return true
		}
	}

	// REMOVED: The overly aggressive detection that was causing loops
	// We no longer detect general patterns like "unchanged", "existing code", etc.
	// because legitimate partial code snippets often contain these words

	return false
}

// IsPartialResponse checks if the code contains partial response markers
func IsPartialResponse(code string) bool {
	lines := strings.Split(code, "\n")
	for _, line := range lines {
		if IsPartialContentMarker(line) {
			return true
		}
	}
	return false
}

func extractFilename(line string) string {
	parts := strings.Split(line, "#")
	if len(parts) < 2 {
		return ""
	}
	// The filename is the first word after the last '#'
	potentialFilename := strings.TrimSpace(parts[len(parts)-1])
	if potentialFilename == "" {
		return ""
	}
	// Take the first component, in case there are comments after filename
	return strings.Fields(potentialFilename)[0]
}

func validateFilename(filename string) bool {
	if filename == "" {
		return false
	}
	parts := strings.Split(strings.Trim(filename, "."), ".")
	return len(parts) > 1 && parts[0] != ""
}

// getExtensionForLanguage returns the file extension for a language
func getExtensionForLanguage(lang string) string {
	extensions := map[string]string{
		"go":         "go",
		"python":     "py",
		"py":         "py",
		"javascript": "js",
		"js":         "js",
		"typescript": "ts",
		"ts":         "ts",
		"java":       "java",
		"c":          "c",
		"cpp":        "cpp",
		"rust":       "rs",
		"sh":         "sh",
		"bash":       "sh",
		"sql":        "sql",
		"html":       "html",
		"css":        "css",
		"json":       "json",
		"yaml":       "yaml",
		"yml":        "yml",
		"xml":        "xml",
	}

	if ext, exists := extensions[lang]; exists {
		return ext
	}
	return "txt" // fallback
}

// generateDefaultFilename creates a default filename based on language and context
func generateDefaultFilename(lang, response string) string {
	// Map languages to extensions
	extensions := map[string]string{
		"go":         ".go",
		"python":     ".py",
		"py":         ".py",
		"javascript": ".js",
		"js":         ".js",
		"typescript": ".ts",
		"ts":         ".ts",
		"java":       ".java",
		"c":          ".c",
		"cpp":        ".cpp",
		"rust":       ".rs",
		"sh":         ".sh",
		"bash":       ".sh",
		"sql":        ".sql",
		"html":       ".html",
		"css":        ".css",
		"json":       ".json",
		"yaml":       ".yaml",
		"yml":        ".yml",
		"xml":        ".xml",
	}

	ext, exists := extensions[lang]
	if !exists {
		return "" // Don't generate filename for unknown languages
	}

	// Try to extract a reasonable filename from the response context
	// Look for existing filenames mentioned in the response
	lines := strings.Split(response, "\n")
	for _, line := range lines {
		// Look for file references like "in filename.go" or "file filename.go"
		if strings.Contains(strings.ToLower(line), strings.ToLower(ext)) {
			words := strings.Fields(line)
			for _, word := range words {
				word = strings.Trim(word, ".,!?()[]{}:;")
				if strings.HasSuffix(strings.ToLower(word), strings.ToLower(ext)) {
					return word
				}
			}
		}
	}

	// Don't generate default filenames - return empty to signal missing filename error
	return ""
}

// tryContentBasedExtraction attempts to extract code from responses without explicit code blocks
func tryContentBasedExtraction(response string) map[string]string {
	result := make(map[string]string)

	// Check if the entire response looks like code
	lines := strings.Split(response, "\n")
	codeLines := 0
	totalLines := len(lines)

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue // Skip empty lines
		}

		// Check if line looks like code (contains programming constructs)
		if looksLikeCode(line) {
			codeLines++
		}
	}

	// If a significant portion looks like code, extract it
	if totalLines > 0 && float64(codeLines)/float64(totalLines) > 0.3 {
		// Try to determine the language from patterns in the code
		lang := detectLanguageFromContent(response)
		if lang != "" {
			filename := generateDefaultFilename(lang, response)
			if filename != "" {
				result[filename] = response
			}
		}
	}

	return result
}

// looksLikeCode checks if a line contains programming constructs
func looksLikeCode(line string) bool {
	// Common programming patterns
	patterns := []string{
		"func ", "function ", "def ", "class ", "import ", "package ",
		"if (", "for (", "while (", "switch ", "case ", "return ",
		"var ", "let ", "const ", "public ", "private ", "protected ",
		"#include", "#define", "using ", "namespace ",
		":=", "==", "!=", "->", "=>", "<-",
		"{", "}", "[];", ");", "();",
	}

	for _, pattern := range patterns {
		if strings.Contains(line, pattern) {
			return true
		}
	}

	return false
}

// detectLanguageFromContent tries to detect the programming language from content
func detectLanguageFromContent(content string) string {
	// Language-specific patterns
	langPatterns := map[string][]string{
		"go":         {"package ", "func ", "import (", "fmt.", ":=", "interface{"},
		"python":     {"def ", "import ", "from ", "if __name__", "class ", "print("},
		"javascript": {"function ", "var ", "let ", "const ", "console.log", "=>"},
		"java":       {"public class", "public static", "System.out", "import java"},
		"c":          {"#include", "int main", "printf", "malloc", "struct "},
		"cpp":        {"#include", "std::", "cout <<", "using namespace", "class "},
		"rust":       {"fn ", "let mut", "println!", "use ", "struct ", "impl "},
		"typescript": {"interface ", "type ", "export ", "import ", "function "},
	}

	for lang, patterns := range langPatterns {
		matches := 0
		for _, pattern := range patterns {
			if strings.Contains(content, pattern) {
				matches++
			}
		}

		// If we find multiple patterns for a language, it's likely that language
		if matches >= 2 {
			return lang
		}
	}

	return "" // Unknown language
}

func GetUpdatedCodeFromResponse(response string) (map[string]string, error) {

	// First, try to parse as patches (new format)
	patches, err := GetUpdatedCodeFromPatchResponse(response)
	if err == nil && len(patches) > 0 {
		updatedCode := make(map[string]string)
		for filename, patch := range patches {
			// For backward compatibility, convert patches to full file content
			// This allows existing code to work with the new patch format
			updatedCode[filename] = patchToFullContent(patch, filename)
		}
		return updatedCode, nil
	}

	// Fall back to original parsing for full file content (old format)
	updatedCode := make(map[string]string)
	var currentFileContent strings.Builder
	var currentFileName string
	var currentLanguage string // New variable to store the language of the current block
	inCodeBlock := false

	lines := strings.Split(response, "\n")

	for i := 0; i < len(lines); i++ {
		line := lines[i]

		isStart, lang := isStartOfCodeBlock(line)
		if !inCodeBlock && isStart {
			filename := extractFilename(line)
			if validateFilename(filename) {
				inCodeBlock = true
				currentFileName = filename
				currentLanguage = lang // Store the detected language
				currentFileContent.Reset()
				continue
			}

			// If no valid filename on the start line, check the next line
			// This handles cases like:
			// ```go
			// # myfile.go
			// ...
			if i+1 < len(lines) {
				filenameOnNextLine := extractFilename(lines[i+1])
				if validateFilename(filenameOnNextLine) {
					inCodeBlock = true
					currentFileName = filenameOnNextLine
					currentLanguage = lang // Store the detected language from the first line
					currentFileContent.Reset()
					i++ // Consume the filename line
					continue
				}
			}

			// Enhanced robustness: If it's a code block without explicit filename,
			// try to use a sensible default based on the language or context
			if lang != "" && lang != "markdown" && lang != "md" {
				defaultFilename := generateDefaultFilename(lang, response)
				if defaultFilename != "" {
					inCodeBlock = true
					currentFileName = defaultFilename
					currentLanguage = lang
					currentFileContent.Reset()
					continue
				} else {
					// No filename could be determined - return error asking LLM to specify filename
					return nil, fmt.Errorf("Code block with language '%s' found but no filename specified. Please include a filename in the code block header like: ```%s # filename.%s", lang, lang, getExtensionForLanguage(lang))
				}
			}
			// If no valid filename and no default can be generated, we ignore it.
		} else if inCodeBlock && isEndOfCodeBlock(line, currentLanguage) { // Pass currentLanguage to the check
			inCodeBlock = false
			if currentFileName != "" {
				fileContent := strings.TrimSuffix(currentFileContent.String(), "\n")

				// Check for partial content markers in the file
				if IsPartialResponse(fileContent) {
					// Note: Partial content detected - may cause issues when applying changes
				}

				updatedCode[currentFileName] = fileContent
				currentFileName = ""
				currentLanguage = "" // Reset language after block ends
			}
		} else if inCodeBlock {
			currentFileContent.WriteString(line + "\n")
		}
	}

	}
	// Final fallback: if no code blocks were found, check if the entire response
	// looks like structured code content that we can extract
	if len(updatedCode) == 0 {
		fallbackContent := tryContentBasedExtraction(response)
		if len(fallbackContent) > 0 {
			for filename, content := range fallbackContent {
				updatedCode[filename] = content
			}
		}
	}

	return updatedCode, nil
}

// patchToFullContent converts a patch to full file content for backward compatibility
func patchToFullContent(patch *Patch, filename string) string {
	// This function now reads the original file and applies the patch to it
	// to produce the complete updated file content

	if len(patch.Hunks) == 0 {
		return ""
	}

	// Read the original file content
	originalContent, err := os.ReadFile(filename)
	if err != nil {
		// If we can't read the original file, fall back to the old behavior
		// but with improved reconstruction
		return fallbackReconstruction(patch)
	}

	// Apply the patch to the original content using the existing patch application logic
	updatedContent, err := applyPatchToContent(patch, string(originalContent))
	if err != nil {
		// If patch application fails, fall back to the improved reconstruction
		for i, hunk := range patch.Hunks {
				i, hunk.OldStart, hunk.OldLines, hunk.NewStart, hunk.NewLines)
		}
		return fallbackReconstruction(patch)
	}

	return updatedContent
}

// PatchToFullContent converts a parsed Patch to full file content.
// It reads the original file at filename and applies the patch. If the original
// file cannot be read or the patch cannot be cleanly applied, it falls back to
// a best-effort reconstruction that preserves added lines and available context.
func PatchToFullContent(patch *Patch, filename string) string {
	return patchToFullContent(patch, filename)
}

// fallbackReconstruction provides improved reconstruction when we can't read the original file
func fallbackReconstruction(patch *Patch) string {
	return reconstructWithBestEffort(patch)
}

// reconstructWithBestEffort attempts to reconstruct the file content as accurately as possible
// when we can't apply the patch to the original file
func reconstructWithBestEffort(patch *Patch) string {
	if len(patch.Hunks) == 0 {
		return ""
	}

	// For single hunk patches, we can do a reasonable reconstruction
	if len(patch.Hunks) == 1 {
		return reconstructSingleHunk(patch.Hunks[0])
	}

	// For multiple hunks, try a different approach
	// Instead of estimating missing lines, we'll concatenate the hunks
	// but preserve the context lines to maintain some structure
	result := []string{}

	for i, hunk := range patch.Hunks {
		if i > 0 {
			result = append(result, "") // Add spacing between hunks
		}

		// Add the hunk content with preserved context
		hunkContent := reconstructSingleHunk(hunk)
		result = append(result, hunkContent)
	}

	return strings.Join(result, "\n")
}

// reconstructSingleHunk reconstructs content from a single hunk
func reconstructSingleHunk(hunk Hunk) string {
	lines := []string{}

	for _, hunkLine := range hunk.Lines {
		switch {
		case strings.HasPrefix(hunkLine, "+"):
			// Add new line
			lines = append(lines, strings.TrimPrefix(hunkLine, "+"))
		case strings.HasPrefix(hunkLine, "-"):
			// Skip removed lines (they're not in the final content)
			continue
		default:
			// Context line - preserve as-is
			lines = append(lines, hunkLine)
		}
	}

	return strings.Join(lines, "\n")
}

// ExtractCodeFromResponse extracts a single code block from an LLM response for a specific language
// This is used for partial editing where we expect just one updated section
func ExtractCodeFromResponse(response, expectedLanguage string) (string, error) {
	lines := strings.Split(response, "\n")
	var codeContent strings.Builder
	inCodeBlock := false
	var currentLanguage string

	for _, line := range lines {
		isStart, lang := isStartOfCodeBlock(line)

		if !inCodeBlock && isStart {
			// Accept the block if it matches the expected language or if no language is specified
			if expectedLanguage == "" || lang == expectedLanguage || lang == "" {
				inCodeBlock = true
				currentLanguage = lang
				continue
			}
		} else if inCodeBlock && isEndOfCodeBlock(line, currentLanguage) {
			// Found the end of the code block
			break
		} else if inCodeBlock {
			// Add this line to the code content
			if codeContent.Len() > 0 {
				codeContent.WriteString("\n")
			}
			codeContent.WriteString(line)
		}
	}

	code := codeContent.String()
	if code == "" {
		return "", fmt.Errorf("no code block found for language %s", expectedLanguage)
	}

	return code, nil
}

// Patch represents a unified diff patch
type Patch struct {
	Filename string
	OldFile  string
	NewFile  string
	Hunks    []Hunk
}

// Hunk represents a single diff hunk
type Hunk struct {
	OldStart int
	OldLines int
	NewStart int
	NewLines int
	Lines    []string
}

// ParsePatchFromDiff parses a unified diff string into a Patch struct
func ParsePatchFromDiff(diffContent, filename string) (*Patch, error) {
	scanner := bufio.NewScanner(strings.NewReader(diffContent))
	patch := &Patch{
		Filename: filename,
		Hunks:    []Hunk{},
	}

	var currentHunk *Hunk
	var inHunk bool

	for scanner.Scan() {
		line := scanner.Text()

		// Parse diff header lines
		if strings.HasPrefix(line, "--- ") {
			patch.OldFile = strings.TrimPrefix(line, "--- ")
			continue
		}
		if strings.HasPrefix(line, "+++ ") {
			patch.NewFile = strings.TrimPrefix(line, "+++ ")
			continue
		}

		// Parse hunk header
		if strings.HasPrefix(line, "@@ ") {
			if currentHunk != nil {
				patch.Hunks = append(patch.Hunks, *currentHunk)
			}

			hunk, err := parseHunkHeader(line)
			if err != nil {
				return nil, fmt.Errorf("failed to parse hunk header: %w", err)
			}
			currentHunk = &hunk
			inHunk = true
			continue
		}

		// Parse hunk content
		if inHunk && currentHunk != nil {
			// Unified diff lines inside a hunk can start with:
			//  ' ' (space) for context lines
			//  '+' for additions
			//  '-' for deletions
			//  '\\ No newline at end of file' special marker which we ignore
			if strings.HasPrefix(line, "\\ No newline at end of file") {
				continue
			}
			if strings.HasPrefix(line, " ") {
				// Context line: store without the leading space to match actual file content
				currentHunk.Lines = append(currentHunk.Lines, strings.TrimPrefix(line, " "))
				continue
			}
			// Additions and deletions are kept as-is (with their +/- prefix)
			currentHunk.Lines = append(currentHunk.Lines, line)
		}
	}

	// Add the last hunk
	if currentHunk != nil {
		patch.Hunks = append(patch.Hunks, *currentHunk)
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("error reading diff content: %w", err)
	}

	return patch, nil
}

// parseHunkHeader parses a hunk header line like "@@ -10,7 +10,7 @@"
func parseHunkHeader(header string) (Hunk, error) {
	// Remove any leading '+' that might be present
	header = strings.TrimPrefix(header, "+")

	// Extract just the range part before any content
	// Format: @@ -old_start,old_count +new_start,new_count @@ [optional content]
	secondAt := strings.Index(header[2:], "@@")
	if secondAt == -1 {
		return Hunk{}, fmt.Errorf("invalid hunk header format: %s", header)
	}
	rangeEnd := secondAt + 2 // Adjust for the offset from header[2:]

	// Get the range part (between the first @@ and the second @@)
	rangePart := strings.TrimSpace(header[2:rangeEnd])
	parts := strings.Fields(rangePart)

	if len(parts) != 2 {
		return Hunk{}, fmt.Errorf("invalid hunk header format: %s", header)
	}

	oldRange := parts[0]
	newRange := parts[1]

	oldStart, oldLines, err := parseRange(oldRange)
	if err != nil {
		return Hunk{}, fmt.Errorf("failed to parse old range: %w", err)
	}

	newStart, newLines, err := parseRange(newRange)
	if err != nil {
		return Hunk{}, fmt.Errorf("failed to parse new range: %w", err)
	}

	return Hunk{
		OldStart: oldStart,
		OldLines: oldLines,
		NewStart: newStart,
		NewLines: newLines,
		Lines:    []string{},
	}, nil
}

// parseRange parses a range string like "-10,7" or "+10,7"
func parseRange(rangeStr string) (start, count int, err error) {
	// Remove +/- prefix
	rangeStr = strings.TrimPrefix(strings.TrimPrefix(rangeStr, "-"), "+")

	parts := strings.Split(rangeStr, ",")
	if len(parts) != 2 {
		return 0, 0, fmt.Errorf("invalid range format: %s", rangeStr)
	}

	start, err = strconv.Atoi(parts[0])
	if err != nil {
		return 0, 0, fmt.Errorf("invalid start line: %s", parts[0])
	}

	count, err = strconv.Atoi(parts[1])
	if err != nil {
		return 0, 0, fmt.Errorf("invalid line count: %s", parts[1])
	}

	return start, count, nil
}

// GetUpdatedCodeFromPatchResponse extracts patches from an LLM response
func GetUpdatedCodeFromPatchResponse(response string) (map[string]*Patch, error) {
	// Optional debug logging of the raw LLM response
	if os.Getenv("LEDIT_DEBUG_PATCH") == "1" {
		_ = os.MkdirAll(".ledit/debug", 0755)
		ts := time.Now().Format("20060102_150405")
		path := fmt.Sprintf(".ledit/debug/llm_patch_response_%s.txt", ts)
		_ = os.WriteFile(path, []byte(response), 0644)
	}
	patches := make(map[string]*Patch)
	var currentPatchContent strings.Builder
	var currentFilename string
	inDiffBlock := false

	lines := strings.Split(response, "\n")

	for i := 0; i < len(lines); i++ {
		line := lines[i]

		// Check for diff block start
		if strings.HasPrefix(line, "```diff") {
			filename := extractFilenameFromDiffLine(line)
			if filename != "" {
				inDiffBlock = true
				currentFilename = filename
				currentPatchContent.Reset()
				continue
			}
		}

		// Check for block end
		if inDiffBlock && (line == "```END" || line == "```") {
			inDiffBlock = false
			if currentFilename != "" && currentPatchContent.Len() > 0 {
				patch, err := ParsePatchFromDiff(currentPatchContent.String(), currentFilename)
				if err != nil {
					continue
				}
				patches[currentFilename] = patch
				if os.Getenv("LEDIT_DEBUG_PATCH") == "1" {
					// Write per-file diff content for debugging
					_ = os.MkdirAll(".ledit/debug", 0755)
					ts := time.Now().Format("20060102_150405")
					fpath := fmt.Sprintf(".ledit/debug/diff_%s_%s.diff", ts, strings.ReplaceAll(currentFilename, string(os.PathSeparator), "_"))
					_ = os.WriteFile(fpath, []byte(currentPatchContent.String()), 0644)
				}
			}
			currentFilename = ""
			continue
		}

		// Collect patch content
		if inDiffBlock {
			if currentPatchContent.Len() > 0 {
				currentPatchContent.WriteString("\n")
			}
			currentPatchContent.WriteString(line)
		}
	}

	return patches, nil
}

// extractFilenameFromDiffLine extracts filename from a line like "```diff # myfile.py"
func extractFilenameFromDiffLine(line string) string {
	parts := strings.Split(line, "#")
	if len(parts) < 2 {
		return ""
	}
	filename := strings.TrimSpace(parts[len(parts)-1])
	if filename == "" {
		return ""
	}
	return strings.Fields(filename)[0]
}

// ApplyPatchToFile applies a patch to a file safely with validation
func ApplyPatchToFile(patch *Patch, filePath string) error {
	// Read the current file content
	currentContent, err := os.ReadFile(filePath)
	if err != nil {
		return fmt.Errorf("failed to read file %s: %w", filePath, err)
	}

	// Apply the patch
	updatedContent, err := applyPatchToContent(patch, string(currentContent))
	if err != nil {
		return fmt.Errorf("failed to apply patch to %s: %w", filePath, err)
	}

	// Validate the patch was applied correctly
	if err := validatePatchApplication(patch, string(currentContent), updatedContent); err != nil {
		return fmt.Errorf("patch validation failed for %s: %w", filePath, err)
	}

	// Write the updated content
	if err := os.WriteFile(filePath, []byte(updatedContent), 0644); err != nil {
		return fmt.Errorf("failed to write updated file %s: %w", filePath, err)
	}

	return nil
}

// applyPatchToContent applies a patch to file content and returns the updated content
func applyPatchToContent(patch *Patch, content string) (string, error) {
	lines := strings.Split(content, "\n")
	result := make([]string, len(lines))
	copy(result, lines)

	// Sort hunks by old start line to process them in order
	sortedHunks := make([]Hunk, len(patch.Hunks))
	copy(sortedHunks, patch.Hunks)
	for i := 0; i < len(sortedHunks)-1; i++ {
		for j := i + 1; j < len(sortedHunks); j++ {
			if sortedHunks[j].OldStart < sortedHunks[i].OldStart {
				sortedHunks[i], sortedHunks[j] = sortedHunks[j], sortedHunks[i]
			}
		}
	}

	// Apply hunks in reverse order to maintain line number accuracy
	for i := len(sortedHunks) - 1; i >= 0; i-- {
		hunk := sortedHunks[i]
		updatedResult, err := applyHunkToLines(result, hunk)
		if err != nil {
			return "", fmt.Errorf("failed to apply hunk at line %d: %w", hunk.OldStart, err)
		}
		result = updatedResult
	}

	return strings.Join(result, "\n"), nil
}

// applyHunkToLines applies a single hunk to the lines array
func applyHunkToLines(lines []string, hunk Hunk) ([]string, error) {
	// Find the matching context in the file
	matchStart, err := findContextMatch(lines, hunk, hunk.OldStart-1)
	if err != nil {
		return lines, fmt.Errorf("context match failed: %w", err)
	}

	// Apply hunk changes directly to the lines
	return applyHunkChanges(lines, hunk, matchStart), nil
}

// findContextMatch finds the exact location where the hunk context matches
func findContextMatch(lines []string, hunk Hunk, startHint int) (int, error) {
	// Extract context lines from hunk (excluding +/- lines)
	var contextLines []string
	for _, line := range hunk.Lines {
		if !strings.HasPrefix(line, "+") && !strings.HasPrefix(line, "-") {
			// Normalize by trimming trailing whitespace for robust matching
			contextLines = append(contextLines, strings.TrimRight(line, " \t"))
		}
	}

	// If no context lines, use the start hint
	if len(contextLines) == 0 {
		return startHint, nil
	}

	// Look for matching context near the hint with a larger window
	windowStart := startHint - 25
	if windowStart < 0 {
		windowStart = 0
	}
	windowEnd := startHint + 25
	if windowEnd >= len(lines) {
		windowEnd = len(lines) - 1
	}

	tryMatch := func(from, to int, ctx []string) (int, bool) {
		for i := from; i <= to; i++ {
			if i+len(ctx) > len(lines) {
				break
			}
			matched := true
			for j, contextLine := range ctx {
				var fileLine string
				if i+j < len(lines) {
					fileLine = strings.TrimRight(lines[i+j], " \t")
				}
				if i+j >= len(lines) || fileLine != contextLine {
					matched = false
					break
				}
			}
			if matched {
				return i, true
			}
		}
		return 0, false
	}

	if pos, ok := tryMatch(windowStart, windowEnd, contextLines); ok {
		return pos, nil
	}

	// Fallback: scan the whole file for the full context
	if pos, ok := tryMatch(0, len(lines)-1, contextLines); ok {
		return pos, nil
	}

	// Sliding-window fallback: try smaller consecutive context blocks (5,3,2,1)
	blockSizes := []int{5, 3, 2, 1}
	for _, k := range blockSizes {
		if k > len(contextLines) {
			continue
		}
		for start := 0; start+k <= len(contextLines); start++ {
			block := contextLines[start : start+k]
			if pos, ok := tryMatch(windowStart, windowEnd, block); ok {
				return pos, nil
			}
			if pos, ok := tryMatch(0, len(lines)-1, block); ok {
				return pos, nil
			}
		}
	}

	// Debug log on failure when enabled
	if os.Getenv("LEDIT_DEBUG_PATCH") == "1" {
		_ = os.MkdirAll(".ledit/debug", 0755)
		ts := time.Now().Format("20060102_150405")
		preview := strings.Join(contextLines, "\n")
		_ = os.WriteFile(
			fmt.Sprintf(".ledit/debug/context_miss_%s.txt", ts),
			[]byte(preview), 0644,
		)
	}

	return 0, fmt.Errorf("could not find matching context for hunk at line %d", hunk.OldStart)
}

// applyHunkChanges applies the actual changes from the hunk
func applyHunkChanges(lines []string, hunk Hunk, matchStart int) []string {
	// Build updated hunk segment by consuming original lines and inserting additions
	updated := []string{}
	consumed := 0

	for _, hunkLine := range hunk.Lines {
		switch {
		case strings.HasPrefix(hunkLine, "-"):
			// deletion consumes one line from original
			// Check if we can safely access this line
			if matchStart+consumed < len(lines) && matchStart+consumed >= 0 {
				consumed++
			} else {
				// If we can't access the line, still count it as consumed to maintain hunk structure
				consumed++
			}
		case strings.HasPrefix(hunkLine, "+"):
			// addition inserts new line
			updated = append(updated, strings.TrimPrefix(hunkLine, "+"))
		default:
			// context: copy original and consume one
			if matchStart+consumed < len(lines) && matchStart+consumed >= 0 {
				updated = append(updated, lines[matchStart+consumed])
			} else {
				// If we can't access the line, just add an empty line to maintain structure
				updated = append(updated, "")
			}
			consumed++
		}
	}

	// Assemble: prefix + updated + suffix to preserve entire file content
	// Calculate capacity with bounds checking to prevent panic
	capacity := len(lines) - consumed + len(updated)
	if capacity < 0 {
		// Log the issue for debugging
		if os.Getenv("LEDIT_DEBUG_PATCH") == "1" {
			fmt.Printf("DEBUG: Negative capacity detected in applyHunkChanges: len(lines)=%d, consumed=%d, len(updated)=%d\n",
				len(lines), consumed, len(updated))
		}
		capacity = 0 // Fallback to 0 if calculation is negative
	}
	if capacity > len(lines)+len(updated) {
		capacity = len(lines) + len(updated) // Cap at reasonable maximum
	}
	result := make([]string, 0, capacity)
	// prefix
	if matchStart >= 0 && matchStart <= len(lines) {
		result = append(result, lines[:matchStart]...)
	} else if matchStart < 0 {
		// If matchStart is negative, don't add any prefix
		// This is handled gracefully
	}
	// updated region
	result = append(result, updated...)
	// suffix
	suffixStart := matchStart + consumed
	if suffixStart < len(lines) && suffixStart >= 0 {
		result = append(result, lines[suffixStart:]...)
	} else if suffixStart < 0 {
		// If suffixStart is negative, append the entire file
		result = append(result, lines...)
	}
	return result
}

// validatePatchApplication validates that the patch was applied correctly
func validatePatchApplication(patch *Patch, originalContent, newContent string) error {
	// Basic validation: ensure content changed
	if originalContent == newContent {
		return fmt.Errorf("patch application resulted in no changes")
	}

	// Validate each hunk was applied
	lines := strings.Split(newContent, "\n")
	for _, hunk := range patch.Hunks {
		if err := validateHunkApplication(hunk, lines); err != nil {
			return fmt.Errorf("hunk validation failed: %w", err)
		}
	}

	return nil
}

// validateHunkApplication validates that a specific hunk was applied correctly
func validateHunkApplication(hunk Hunk, lines []string) error {
	// Find added lines in the hunk
	var addedLines []string
	for _, line := range hunk.Lines {
		if strings.HasPrefix(line, "+") {
			addedLines = append(addedLines, strings.TrimPrefix(line, "+"))
		}
	}

	// Verify added lines exist in the new content
	for _, addedLine := range addedLines {
		found := false
		for _, line := range lines {
			if line == addedLine {
				found = true
				break
			}
		}
		if !found {
			return fmt.Errorf("added line not found in new content: %s", addedLine)
		}
	}

	return nil
}

// PatchError represents different types of patch application errors
type PatchError struct {
	Type        string
	File        string
	Description string
	Suggestion  string
	Err         error
}

func (pe *PatchError) Error() string {
	return fmt.Sprintf("%s error in %s: %s. %s", pe.Type, pe.File, pe.Description, pe.Suggestion)
}

func (pe *PatchError) Unwrap() error {
	return pe.Err
}

// NewPatchError creates a new patch error with helpful suggestions
func NewPatchError(errorType, file, description, suggestion string, err error) *PatchError {
	return &PatchError{
		Type:        errorType,
		File:        file,
		Description: description,
		Suggestion:  suggestion,
		Err:         err,
	}
}

// EnhancedApplyPatchToFile applies a patch with enhanced error handling and recovery
func EnhancedApplyPatchToFile(patch *Patch, filePath string) error {
	// Read the current file content
	currentContent, err := os.ReadFile(filePath)
	if err != nil {
		if os.IsNotExist(err) {
			return NewPatchError("FileNotFound", filePath, "Target file does not exist", "Ensure the file path is correct and the file exists", err)
		}
		return NewPatchError("ReadError", filePath, "Failed to read file", "Check file permissions and path", err)
	}

	// Validate patch before applying
	if err := validatePatchBeforeApply(patch, filePath); err != nil {
		return err
	}

	// Apply the patch
	updatedContent, err := applyPatchToContent(patch, string(currentContent))
	if err != nil {
		return NewPatchError("ApplyError", filePath, "Failed to apply patch", "The patch may be malformed or conflict with file content", err)
	}

	// Validate the patch was applied correctly
	if err := validatePatchApplication(patch, string(currentContent), updatedContent); err != nil {
		return NewPatchError("ValidationError", filePath, "Patch validation failed", "The patch may not have been applied correctly", err)
	}

	// Create backup before writing
	backupPath := filePath + ".patch_backup"
	if err := os.WriteFile(backupPath, currentContent, 0644); err != nil {
		return NewPatchError("BackupError", filePath, "Failed to create backup", "Ensure write permissions in the directory", err)
	}

	// Write the updated content
	if err := os.WriteFile(filePath, []byte(updatedContent), 0644); err != nil {
		// Try to restore from backup
		os.WriteFile(filePath, currentContent, 0644)
		return NewPatchError("WriteError", filePath, "Failed to write updated file", "Check file permissions. Backup restored", err)
	}

	// Clean up backup on success
	os.Remove(backupPath)

	return nil
}

// validatePatchBeforeApply performs pre-application validation
func validatePatchBeforeApply(patch *Patch, filePath string) error {
	if patch == nil {
		return NewPatchError("InvalidPatch", filePath, "Patch is nil", "Ensure the patch was parsed correctly", nil)
	}

	if len(patch.Hunks) == 0 {
		return NewPatchError("EmptyPatch", filePath, "Patch contains no hunks", "The patch may be empty or malformed", nil)
	}

	// Validate each hunk
	for i, hunk := range patch.Hunks {
		if len(hunk.Lines) == 0 {
			return NewPatchError("EmptyHunk", filePath, fmt.Sprintf("Hunk %d is empty", i), "Remove empty hunks from the patch", nil)
		}

		// Check for context lines
		hasContext := false
		for _, line := range hunk.Lines {
			if !strings.HasPrefix(line, "+") && !strings.HasPrefix(line, "-") {
				hasContext = true
				break
			}
		}
		if !hasContext {
			return NewPatchError("NoContext", filePath, fmt.Sprintf("Hunk %d has no context lines", i), "Add context lines around changes for reliable application", nil)
		}
	}

	return nil
}
