{
  "name": "lmstudio",
  "endpoint": "http://127.0.0.1:1234/v1/chat/completions",
  "auth": {
    "type": "bearer",
    "env_var": ""
  },
  "headers": {},
  "defaults": {
    "model": "qwen3-coder:30b",
    "temperature": 0.7,
    "max_tokens": -1,
    "top_p": 1.0
  },
  "message_conversion": {
    "include_tool_call_id": false,
    "convert_tool_role_to_user": false,
    "reasoning_content_field": ""
  },
  "streaming": {
    "format": "sse",
    "chunk_timeout_ms": 300000,
    "done_marker": "[DONE]"
  },
  "models": {
    "default_context_limit": 32768,
    "model_overrides": {
      "qwen2.5-coder-32b-instruct": 32768,
      "qwen3-coder:30b": 128768,
      "llama-3.1-70b-instruct": 128072,
      "llama-3-70b-instruct": 8192,
      "mistral-7b-instruct": 32768,
      "yi-34b-chat": 4096
    },
    "pattern_overrides": [
      {
        "pattern": ".*llama-3\\.1.*",
        "context_limit": 128072
      },
      {
        "pattern": ".*llama-3.*",
        "context_limit": 8192
      },
      {
        "pattern": ".*qwen2\\.5.*",
        "context_limit": 32768
      },
      {
        "pattern": ".*codellama.*",
        "context_limit": 16384
      },
      {
        "pattern": ".*mistral.*",
        "context_limit": 32768
      }
    ],
    "supports_vision": true,
    "vision_model": "gemma-3-12b-it-qat",
    "default_model": "qwen3-coder:30b",
    "available_models": []
  },
  "retry": {
    "max_attempts": 3,
    "base_delay_ms": 1000,
    "backoff_multiplier": 2.0,
    "max_delay_ms": 30000,
    "retryable_errors": ["rate_limit_exceeded", "temporary_error", "timeout"]
  },
  "cost": {
    "input_token_cost": 0.0,
    "output_token_cost": 0.0,
    "currency": "USD"
  }
}